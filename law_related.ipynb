{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lawsuit related to IPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the csv file in the target file\n",
    "file_dir = r\"D:/polyu/data_polyu/law_suit_data/\"\n",
    "\n",
    "raw_data = pd.read_csv(file_dir + \"matching_data.csv\")\n",
    "raw_data = raw_data[raw_data[\"ipo_date\"].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtained from WRDS CRSP/Compustat Merged Database and provides \"gvkey\", \"PERMNO\" and \"ipo date\"\n",
    "match_data = pd.read_csv(file_dir +  \"matching.csv\", usecols=[\"LPERMNO\", \"gvkey\", \"tic\", \"LINKENDDT\", \"ipodate\"])\n",
    "match_data.rename(columns={\"tic\":\"Ticker\"}, inplace=True)\n",
    "\n",
    "# take the Ticker with newest date: LINKENDDT\n",
    "match_data[\"Max_LINKENDDT\"] = match_data.groupby(\"Ticker\")[\"LINKENDDT\"].transform(\"max\")\n",
    "match_data = match_data[match_data[\"Max_LINKENDDT\"] == match_data[\"LINKENDDT\"]]\n",
    "match_data = match_data.drop(columns=[\"Max_LINKENDDT\", \"LINKENDDT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provides \"PERMNO\" and its corresponding using period: \"NAMEDT\",\"NAMEENDT\". \n",
    "full_data = pd.read_sas(file_dir + \"msenames.sas7bdat\")\n",
    "full_data = full_data[[\"NAMEDT\", \"NAMEENDT\", \"TICKER\", \"PERMNO\"]].drop_duplicates()\n",
    "full_data.rename(columns={\"TICKER\": \"Ticker\"}, inplace=True)\n",
    "\n",
    "# take the Ticker with newest date: LINKENDDT\n",
    "full_data['MAX_NAMEENDT'] = full_data.groupby(['Ticker', 'PERMNO'])['NAMEENDT'].transform('max')\n",
    "full_data = full_data[full_data['NAMEENDT'] == full_data['MAX_NAMEENDT']]\n",
    "full_data.drop(columns=['MAX_NAMEENDT'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer the data type from \"bytes string\" to \"string\"\n",
    "def bytes_to_string(b):\n",
    "    return b.decode('utf-8') if isinstance(b, bytes) else b\n",
    "\n",
    "ipo_data = ipo_data.applymap(bytes_to_string)\n",
    "full_data = full_data.applymap(bytes_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(raw_data[raw_data['Filing Name'].str.contains(':')]))\n",
    "exclude_exchanges = [\"Open-end Fund\", \"Privately Traded\", \"Pink Sheets\", \"ETF\"]\n",
    "# print(len(raw_data[raw_data['Exchange'].isin(exclude_exchanges)]))\n",
    "raw_data = raw_data[~raw_data['Filing Name'].str.contains(':')]\n",
    "raw_data = raw_data[~raw_data['Exchange'].isin(exclude_exchanges)]\n",
    "raw_data = raw_data.dropna(subset=[\"Ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ipo(raw_data, data, column_need):\n",
    "    data = data[[\"Trade_Date\", column_need, \"gvkey\"]]\n",
    "    data[\"Max_Trade_Date\"] = data.groupby(column_need)[\"Trade_Date\"].transform(\"max\")\n",
    "    data = data[data[\"Trade_Date\"] == data[\"Max_Trade_Date\"]]\n",
    "    data = data.drop(columns=[\"Max_Trade_Date\"])\n",
    "    \n",
    "    if column_need != \"Ticker\":\n",
    "        data.rename(columns={column_need: \"Ticker\"}, inplace=True)\n",
    "    matched_data = pd.merge(raw_data, data, on=[\"Ticker\"], how=\"left\")\n",
    "    return matched_data\n",
    "\n",
    "aa = get_ipo(raw_data, ipo_data, \"Ticker\")\n",
    "aa = get_ipo(aa, ipo_data, \"tic\")\n",
    "aa[\"gvkey\"] = aa[\"gvkey_x\"].combine_first(aa[\"gvkey_y\"])\n",
    "aa = aa.drop(columns=[\"gvkey_x\", \"gvkey_y\", \"Trade_Date_x\"])\n",
    "aa[\"Filing Date\"] = pd.to_datetime(aa[\"Filing Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv(file_dir + \"matching_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bb[\"ipo_date\"].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
